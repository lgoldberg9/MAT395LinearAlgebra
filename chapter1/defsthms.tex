\chapter{Vector Spaces}
\section{Vector Spaces}
\section{Subspaces}

Below is a proof of Theorem 1.1.

\begin{theorem}
\label{subspace}
A nonempty subset $S$ of a vector space $V$ is a subspace of $V$ if and only if $S$ is closed under addition and scalar multiplication or, equivalently, for all $a,b\in F$ and $u,v\in S$, $au+bv\in S$.
\end{theorem}

\begin{proof}
Suppose $S$ is a subspace of $V$. Then by definition $S$ is a vector space over $F$ with vector addition $S\times S\rightarrow V$ and with scalar multiplication $F\times S\rightarrow V$. Let $u,v\in S$ and $a,b\in F$. By definition of scalar multiplication, $au\in S$ and $bv\in S$. Also from the defintion of vector addition on $S$, $au+bv\in S$. Hence $S$ is closed under linear combination.\\

On the other hand, let $S\subseteq V$ be an arbitrary nonempty subset that is closed under linear combination. Since $V$ is a vector space, vector addition associates and commutes on the elements of a nonempty subset $S$. $S$ is nonempty, so fix $v\in S$. Because $S$ is closed under linear combination and $0u=0$ for any $u\in V$ by Exercise 1 from this chapter, we conclude that $0v=0\in S$. Now since $V$ is a vector space, fix $w\in V$ for which $v+w = 0$. Since $0\in S$, 
\[v + w = 0 \Leftrightarrow w = (-1)v \in S.\]
Again since $V$ is a vector space, scalar multiplication associates and distributes on the elements of a nonempty subset $S$. Since $F$ is a field and $V$ is a vector space, $1\neq 0$ and $1\in F$ with the property that $1v=v$ for all $v\in V$. Since $S\subseteq V$, $1v=v$ for all $v\in S$. Hence $S$ is a subspace of $V$.
\end{proof}

The proof of Theorem 1.2 can use a little more elaboration. Following the conclusion of the proof, it should state the following.

\begin{proof}
Since $F$ is an infinite field, the infinite set $A$ cannot be the union of finitely many proper subspaces since each subspaces of $V$ only contains at most one element of $A$. Hence $V\neq S_1\cup S_2\cup\cdots\cup S_n$.
\end{proof}

\section{Direct Sums}

\begin{theorem}
The set $S(V)$ of all subspaces of a vector space $V$ is a complete lattice under set inclusion, with samllest element $\{0\}$, and largest element $V$, meet 
\[
	\sup\{S_i\mid i\in K\}=\bigcap_{i\in K} S_i
\]
and join
\[	
	\lub\{S_i\mid i\in K\}=\sum_{i\in K} S_i = \{s_1+\ldots+s_n\mid s_j\in\bigcup_{i\in K} S_i\}
\]
\end{theorem}

\begin{proof}
Let $V$ be a vector space over a field $F$. We begin by showing that $S(V)$ is a lattice under set inclusion. We will first establish that every collection of sets has a greatest lower bound and a least upper bound under set inclusion.\\

We claim that the greatest lower bound of a collection of subspaces is a subspace formed by the intersection over those subspaces. Let $P=\{S_i\mid i\in K\}$, where $K$ is an indexing set, be a family of subspaces of $V$. Since each $S_i$ if a subspace, each contains 0, so $\bigcap P$ is nonempty. Therefore, fix $a,b\in F$ and $u,v\in\bigcap P$. From set theory, $u,v\in S_i$ for each $i\in K$. Since each $S_i$ is a subspace, $au+bv\in S_i$ for each $i\in K$ by Theorem \ref{subspace}. Thus, $au+bv\in\bigcap P$ and so $\bigcap P$ is a subspace by Theorem \ref{subspace}.\\

Now that $\bigcap P\in S(V)$, we can show that it is the greatest lower bound of $P$. Clearly, $\bigcap P\subseteq S_i$ for each $i\in K$ by definition of intersection. Let $T$ be an arbitrary lower bound of $P$. Since $T$ is a lower bound of $P$, $T$ is contained in every $S\in P$. As such if $v\in T$, then $v\in S_i$ for each $i$. Therefore $v\in\bigcap P$ and so $T\subseteq\bigcap P$.\\

Hence $\glb\{S_i\mid i\in K\}=\bigcap_{i\in K} S_i$ is the greatest lower bound of any collection of subspaces $\{S_i\mid i\in K\}$. Now we will show that every collection of subspaces has a least upper bound under set inclusion. Let $P=\{S_i\mid i\in K\}$. We claim that the least upper bound over a collection of sets is the set
\[
	\lub P = \sum P 
\]
for which $\sum P$ is the set of finite sums of elements in $\bigcup P$.\\

We begin by showing that $\sum P$ is a subspace of $V$. Notice first that by definition of $\sum P$ that $\bigcup P\subseteq\sum P$. Therefore if $\sum P$ is a subspace of $V$, $\sum P$ is an upper bound of $P$. Recall that each $S\in P$ is a subspace of $V$, so $0\in S$. Thus $\sum P$ is nonempty. Therefore fix $a,b\in F$ and $u,v\in\sum P$. Because $\sum P$ contains the union of each $S\in P$, we encounter two different cases.
\begin{enumerate}[label=\textit{Case \arabic*:}]
\item Suppose there is a $j\in K$ with $u,v\in S_j$. Since $S_j$ is a subspace, $au+bv\in S_j$ and so $au+bv\in\sum P$. 
\item Suppose $u$ and $v$ hail from distinct subspaces, that is $u\in S_i\backslash S_j$ and $v\in S_j\backslash S_i$ for some $i,j\in K$. Since $S_i$ and $S_j$ are closed under scalar multiplication, $au\in S_i\backslash S_j$ and $bv\in S_j\backslash S_i$. Now because $\sum P$ is closed under finite sums of vectors, and $au,bv\in\bigcup P$, $au+bv\in\sum P$. Hence $\sum P$ is a subspace of $V$ by Theorem \ref{subspace}.
\end{enumerate}

Last we show that $\sum P$ is the smallest upper bound. Let $T\in S(V)$ be an upper bound of $P$. Then $S\subseteq T$ for each $S\in P$. Because $S\subseteq T$ for all $S\in P$, if $\{s_j\}_{j=1}^n\subseteq\bigcup P$ is a finite set of elements, then $\sum_{j=1}^n\{s_j\}\in T$ since $T$ is closed under linear combination. Given that $\{s_j\}_{j=1}^n$ was an arbitrary finite subset of elements of $\bigcup P$, we conclude that all finite sums of elements in $\bigcup P$ are in $T$. Hence $\sum P\subseteq T$. Therefore $\sum P$ is the least upper bound of $P$ and thus every collection of subspaces of $V$ has a least upper bound under set inclusion.\\

Therefore $S(V)$ is a lattice under set inclusion. Finally we need to show that $S(V)$ is a complete lattice. To do this, we need to show that $\{0\}$ is the smallest element of $S(V)$ and $V$ is the largest element of $S(V)$. \\

Notice that $\{0\}\subseteq S$ for all $S\in S(V)$ by definition of subspace. Therefore if $T\in S(V)$ is smaller than $\{0\}$, $T$ cannot contain 0 and is thus not in $S(V)$. Therefore $\{0\}$ is the smallest element of $S(V)$.\\

Because every $S\in S(V)$ is a subspace of $V$, every $S$ is a subset of $V$. Now if $T\in S(V)$ is such that $V\subseteq T$, then $V=T$ since $T\in S(V)$. Hence $V$ is the largest element of $S(V)$.\\

Thus $S(V)$ is a complete lattice as desired.
\end{proof}

Below, I've rewritten the proof of Theorem 1.5 for clarity.

\begin{theorem}
Let $\cF=\{S_i\mid i\in I\}$ be a family of distinct subspaces of $V$. The following are equivalent:
\begin{enumerate}[label=\textit{\arabic*)}]
	\item \textbf{(Independence of the family)} For each $i\in I$,
	\[
		S_i\cap\left(\sum_{j\neq i} S_j\right)=\{0\}	
	\]
	
	\item \textbf{(Uniqueness of expression for 0)} The zero vector $\vec{0}$ cannot be written as a sum of nonzero vectors from distinct subspaces of $\cF$.
	
	\item \textbf{(Uniqueness of expression)} Every nonzero vector $v\in V$ has a unique expression as a sum
	\[
		v = s_{\sigma(1)} + \cdots + s_{\sigma(n)}	
	\]
	of nonzero vectors from distinct subspaces of $\cF$ for any permutation $\sigma\colon\{1,2,\ldots,n\}\rightarrow\{1,2,\ldots,n\}$.
\end{enumerate}
Hence, a sum
\[
	V = \sum_{i\in I} S_i
\]
is direct if and only if any one of 1)-3) holds.
\end{theorem}

\begin{proof}
Suppose that 2) fails, that is if $\{j_i\}_{i=1}^n\subseteq I$ is a finite indexing set, then
\[
	0 = s_{j_1} + \cdots + s_{j_n}
\]
where the nonzero vectors $s_{j_i}$ are from distinct subspaces $S_{j_i}$. Then $n>1$ and so
\[
	-s_{j_1} = s_{j_2} + \cdots s_{j_n}
\]
which violates 1) because $s_{j_1}$ is now the combination of vectors from distinct subspaces. In other words, $s_{j_1}\in S_i\cap \left(\sum_{i\in I} S_i\right)$. Hence 1) implies 2). Suppose 2) holds and
\[
	v = s_1 + \cdots + s_n \text{ and } v = t_1 + \cdots t_m
\]
where the terms are nonzero and the $s_i$'s belong to distinct subspaces in $\cF$ and similarly for the $t_i$'s, then 
\[
	0 = s_1 + \cdots + s_n + t_1 + \cdots + t_m.
\]
By collecting terms from the same subspaces, we may write
\[
	0 = (s_{i_1} - t_{i_1}) + \cdots (s_{i_k} - t_{i_k}) + s_{i_{k+1}} + \cdots + s_{i_n} + t_{i_{k+1}} + \cdots + t_{i_m}
\]
with index set $\{i_k\mid 1\leq k\leq\max\{n,m\}\}$. 2) implies that $n = m = k$ and $s_{i_u} = t_{i_u}$ for all $u\in\{1,\ldots,k\}$. Hence 2) implies 3).

Finally, suppose that there is a nonzero $v\in V$ with
\[
	v\in S_i\cap\left(\sum_{j\neq i} S_j\right)
\]
Then $v=s_i$ for some $s_i\in S_i$ and
\[
	s_i = s_{j_1} + \cdots s_{j_n}
\]
where $s_{j_k}\in S_{j_k}$ are nonzero. But this violates 3) because $s_i\in S$ now has two representations as sums of vectors $s_{j_i}$ from distinct subspaces.

\end{proof}

\section{Spanning Sets}
\begin{theorem}
A finite set $S=\{v_1,v_2,\ldots,v_n\}$ of vectors in $V$ is a basis of $V$ if and only if 
\[
	V = \left\langle v_1\right\rangle \oplus \cdots \oplus \left\langle v_n\right\rangle.
\]

Assume $V = \left\langle v_1\right\rangle \oplus \cdots \oplus \left\langle v_n\right\rangle$. Let $u\in V$ be arbitrary. Then $v$ is a linear combination of vectors from the spans of each $v_i$ with nonzero coefficients
\[
	u = r_1v_1 + r_2v_2 + \cdots + r_nv_n
\]
Because the family of spans is a direct sum, $u$ has a unique expression of vectors from the family $v_i$ by Theorem 1.5. Therefore $v$ is an essentially unique combination of vectors from $S$ and hence is a basis.

If $V \neq \left\langle v_1\right\rangle \oplus \cdots \oplus \left\langle v_n\right\rangle$, then $S$ ceases to be a basis. One of two conditions fails:
\begin{enumerate}[label=\textit{Case \arabic*:}]
\item If $\displaystyle\sum_{i=1}^n \left\langle v_i\right\rangle\subset V$, then $S$ does not span $V$.

\item Alternatively, $\displaystyle\left\langle v_i\right\rangle \cap \sum_{j\neq i} \left\langle v_j\right\rangle \neq \{0\}$. In this case, an arbitrary nonzero $\displaystyle v\in \left\langle v_i\right\rangle\cap \sum_{j\neq i} \left\langle v_j\right\rangle$ does not have a unique expression as the sum of vectors from each span $\left\langle v_i\right\rangle$. Thus $v$ is not an essentially unique combination of vectors in $S$, so $S$ is not linearly independent.
\end{enumerate}
\end{theorem}

\section{The Dimension of a Vector Space}
\section{Ordered Bases and Coordinate Matrices}
\section{The Row and Column Spaces of a Matrix}
\section{The Complexification of a Real Vector Space}
